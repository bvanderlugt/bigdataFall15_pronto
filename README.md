# Project for Big Data fall 2015
## Analysing the Pronto Bike Share Program

Using the workflow from the Coursera Twitter blog post: http://blog.cloudera.com/blog/2012/09/analyzing-twitter-data-with-hadoop/

Applying it to pronto live data feed: https://secure.prontocycleshare.com/data/stations.json

Configuration notes:

* rembember to assume hdfs user "su hdfs" to run hdfs commands, including flume agent
* depends on direcotries: hdfs = /flume/pronto
